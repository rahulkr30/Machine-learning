{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error ,r2_score\n",
    "from sklearn.datasets import load_diabetes ,make_regression\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val sklearn implementaion \n",
    "\n",
    "- estimator: The machine learning model or estimator object that you want to evaluate. It should have a fit method to train the model and a score method or a specified scoring metric for evaluation.\n",
    "\n",
    "- X: The input features or data matrix.\n",
    "\n",
    "- y: The target variable or output labels. It is optional and can be omitted for unsupervised learning tasks.\n",
    "\n",
    "- scoring: The evaluation metric to use. It can be a predefined string metric (e.g., \"accuracy\", \"f1\", \"mean_squared_error\") or a custom scoring function. If scoring is not specified, the estimator's default score method is used.\n",
    "\n",
    "- cv: The cross-validation strategy or the number of folds to use. It can be an integer (e.g., 5 for 5-fold cross-validation) or an object that implements a specific cross-validation scheme (e.g., KFold, StratifiedKFold). If cv is None, it uses the default 5-fold cross-validation.\n",
    "\n",
    "- n_jobs: The number of parallel jobs to run during cross-validation. It allows for faster computation by parallelizing the process. Setting n_jobs to -1 uses all available processors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem with hold out approch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state is 10\n",
      "Mean Squared Error: 2911.8118861191774\n",
      "R2 score -> 0.5341988244945842 \n",
      "\n",
      "random state is 20\n",
      "Mean Squared Error: 3461.6627862550476\n",
      "R2 score -> 0.4179775463198647 \n",
      "\n",
      "random state is 30\n",
      "Mean Squared Error: 3287.479348826673\n",
      "R2 score -> 0.4653044632644133 \n",
      "\n",
      "random state is 42\n",
      "Mean Squared Error: 2900.19362849348\n",
      "R2 score -> 0.4526027629719197 \n",
      "\n",
      "random state is 38\n",
      "Mean Squared Error: 3242.190913590777\n",
      "R2 score -> 0.25754992209749294 \n",
      "\n",
      "random state is 108\n",
      "Mean Squared Error: 2443.813726634741\n",
      "R2 score -> 0.5951326918629855 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "random_states=[10,20,30,42,38,108]\n",
    "\n",
    "for i in random_states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i) \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    print(\"random state is {}\".format(i))\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    r2=r2_score(y_test, y_pred)\n",
    "    print('R2 score ->',r2 ,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</b> we can clearly see the variablity in r2 score when the randomstate is changing ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create Leave-One-Out Cross-Validator\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "# Initialize an empty list to store the evaluation results\n",
    "Scores= cross_val_score(model,X,y,cv=cv,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001.7528469994304"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(Scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqrt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\data science mentorship program\\Module 5 ml\\machine learning\\Model_evalution\\Validation.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sqrt(\u001b[39m3001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sqrt' is not defined"
     ]
    }
   ],
   "source": [
    "sqrt(3001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-one-out cross-validation offers the following pros:\n",
    "\n",
    "1. It provides a much less biased measure of test MSE compared to using a single test set because we repeatedly fit a model to a dataset that contains n-1 observations.\n",
    "2. It tends not to overestimate the test MSE compared to using a single test set.\n",
    "\n",
    "However, leave-one-out cross-validation comes with the following cons:\n",
    "\n",
    "1. It can be a time-consuming process to use when n is large.\n",
    "2. It can also be time-consuming if a model is particularly complex and takes a long time to fit to a dataset.\n",
    "3. It can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\data science mentorship program\\Module 5 ml\\machine learning\\Model_evalution\\Validation.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m Scores\u001b[39m=\u001b[39m cross_val_score(model,X,y,cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold, score \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(Scores, start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/data%20science%20mentorship%20program/Module%205%20ml/machine%20learning/Model_evalution/Validation.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# model\n",
    "model = LinearRegression()\n",
    "Scores= cross_val_score(model,X,y,cv=5,scoring='r2')\n",
    "\n",
    "for fold, score in enumerate(Scores, start=1):\n",
    "    print(f\"Fold {fold}: {score}\")\n",
    "\n",
    "#Avg score \n",
    "avg_score = Scores.mean()\n",
    "print(\"Average Score - \", avg_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experminting with different k_fold and try to find the variablity of accuracy when incresing the kfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: 0.48231643590864215\n",
      "Fold 11: 0.48231643590864215\n",
      "Fold 5: 0.48231643590864215\n",
      "Fold 7: 0.48231643590864215\n",
      "Fold 100: 0.48231643590864215\n"
     ]
    }
   ],
   "source": [
    "n_folds = [5,11,5,7,100]\n",
    "avg_scores = []\n",
    "scores_=[]\n",
    "\n",
    "\n",
    "X, y = make_regression(n_samples=10000, n_features=3, noise=20, random_state=42)\n",
    "# Perform cross-validation for each number of folds\n",
    "for i in n_folds:\n",
    "    kfold = KFold(n_splits=i, shuffle=True, random_state=i)\n",
    "    model = LinearRegression()\n",
    "    scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')\n",
    "    scores_.append(scores)\n",
    "    avg_score = Scores.mean()\n",
    "    avg_scores.append(avg_score)\n",
    "\n",
    "plt.plot(n_folds, avg_scores, marker='o')\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Bias Reduction with Increasing Folds')\n",
    "plt.show()\n",
    "\n",
    "for fold, score in zip(n_folds,avg_scores):\n",
    "    print(f\"Fold {fold}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at every fold result is same but increasing the k_fold may lead the following prblem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smaller Validation Sets: As the number of folds increases, each validation set becomes smaller. With a larger k, a larger portion of the data is used for validation in each iteration, resulting in less data available for training the model. Smaller validation sets can provide a more precise estimate of model performance on unseen data but may also lead to higher variability in the evaluation scores.\n",
    "\n",
    "- Increased Computational Cost: Increasing the value of k also increases the computational cost of k-fold cross-validation. With each fold, the model needs to be trained and evaluated, resulting in more iterations. This can be time-consuming and resource-intensive, especially for large datasets or complex models. Therefore, higher values of k may lead to longer execution times.\n",
    "\n",
    "- Higher Variability in Performance: With more folds, the cross-validation estimate of model performance becomes more precise but can also increase the variability in performance scores across the folds. Each fold represents a different validation set, and the model's performance can vary depending on the specific subset used for validation. With a higher number of folds, the model's performance may exhibit more variance due to the increased number of validation sets.\n",
    "\n",
    "- Reduced Bias in Performance Estimate: Increasing the number of folds can reduce the bias in the performance estimate of the model. By using more subsets as validation sets, the estimate becomes less dependent on the specific train-test split and is less biased towards any particular portion of the data. This can provide a more accurate representation of the model's performance on unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Advantage and disadvantage of KFolod `\n",
    "\n",
    "#### Advantages of k-fold cross-validation:\n",
    "\n",
    "1. Better performance estimation: k-fold cross-validation provides a more robust estimate of a model's performance compared to a single train-test split. It reduces the impact of variability in the data by averaging the results across multiple folds.\n",
    "\n",
    "2. Efficient use of data: k-fold cross-validation allows you to make the most out of your available data. By using all data points for both training and testing in different folds, you maximize the utilization of the dataset.\n",
    "\n",
    "3. Model selection and hyperparameter tuning: k-fold cross-validation is commonly used for model selection and hyperparameter tuning. It enables fair and unbiased comparison of different models or hyperparameter configurations by using the same folds for evaluation.\n",
    "\n",
    "#### Disadvantages and limitations of k-fold cross-validation:\n",
    "\n",
    "1. Computational cost: The computational cost of k-fold cross-validation can be higher compared to a single train-test split. As the number of folds (k) increases, the training and evaluation process needs to be repeated k times, which can be time-consuming for large datasets or complex models.\n",
    "\n",
    "2. Potential bias in small datasets: In small datasets, k-fold cross-validation might introduce bias due to the limited number of samples available for training and testing. The performance estimates may not be representative of the model's true generalization performance.\n",
    "\n",
    "3. Data leakage in feature engineering: If feature engineering techniques are applied based on the entire dataset before cross-validation, there is a risk of data leakage. Information from the testing folds could unintentionally influence the feature engineering process and lead to overly optimistic performance estimates.\n",
    "\n",
    "4. Difficulty in handling class imbalance: k-fold cross-validation alone does not handle class imbalance issues in the dataset. If the dataset has imbalanced classes, the performance evaluation may still be biased towards the majority class unless additional techniques like stratified sampling or stratified cross-validation are used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  +-------------------------------+\n",
    "  |          Data Samples        |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |        Stratified Split       |\n",
    "  |       (k=5 in this example)   |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |          Fold 1               |\n",
    "  |        Train: Folds 2-5       |\n",
    "  |        Test: Fold 1           |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |          Fold 2               |\n",
    "  |        Train: Folds 1, 3-5    |\n",
    "  |        Test: Fold 2           |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |          Fold 3               |\n",
    "  |        Train: Folds 1-2, 4-5  |\n",
    "  |        Test: Fold 3           |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |          Fold 4               |\n",
    "  |        Train: Folds 1-3, 5    |\n",
    "  |        Test: Fold 4           |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |          Fold 5               |\n",
    "  |        Train: Folds 1-4       |\n",
    "  |        Test: Fold 5           |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |    Performance Aggregation    |\n",
    "  +-------------------------------+\n",
    "                |\n",
    "                v\n",
    "  +-------------------------------+\n",
    "  |      Overall Performance      |\n",
    "  +-------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Generate a large dummy dataset with imbalanced output\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(33)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 10000\n",
    "\n",
    "# Generate features (dummy data)\n",
    "X = np.random.rand(n_samples, 5)\n",
    "\n",
    "# Generate imbalanced output\n",
    "y = np.concatenate([np.zeros(9000), np.ones(1000)])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=22,test_size=0.2)\n",
    "\n",
    "# Number of folds\n",
    "k = 5  \n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "model = LogisticRegression()\n",
    "\n",
    "cross_val=cross_val_score(model,X_train,y_train,cv=skf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89875 , 0.89875 , 0.89875 , 0.89875 , 0.898125])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
