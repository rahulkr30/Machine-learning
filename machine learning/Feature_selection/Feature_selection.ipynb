{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"text-align:center;background-color: pink; padding: 20px;color: Black\"> <b>Feature selection</b></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>``Feature selection``<b> \n",
    "It is a technique used in machine learning to identify and select the most relevant and informative features from a dataset. The goal of feature selection is to improve the performance and accuracy of machine learning models by reducing the dimensionality of the data and removing irrelevant or redundant features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The <b>`curse of dimensionality`</b> refers to the fact that many machine learning algorithms face significant challenges when dealing with high-dimensional data. As the number of dimensions (or features) in a dataset increases, the volume of the data space grows exponentially, making it difficult to obtain a representative sample of the data and to accurately estimate relationships between variables.\n",
    "\n",
    "\n",
    "\n",
    "<span style='color:pink'>This can lead to several issues, including</span>\n",
    "\n",
    "- `Sparsity`: As the number of dimensions increases, the available data become more sparse, making it difficult to identify patterns and relationships in the data.\n",
    "\n",
    "\n",
    "- `Overfitting:` High-dimensional data can lead to overfitting, where a machine learning model becomes overly complex and fits the noise in the data instead of the underlying patterns.\n",
    "\n",
    "- `Increased computational complexity: ` As the dimensionality of the data increases, the computational requirements for processing and analyzing the data also increase, leading to slower training times and increased resource usage.\n",
    "\n",
    "> **To address the curse of dimensionality, several techniques can be used, including feature selection, dimensionality reduction, and regularization. These techniques can help to reduce the number of features and improve the performance and efficiency of machine learning models when dealing with high-dimensional data.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Features\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Variance Threshold Feature Selection`\n",
    "Variance threshold feature selection is a filter-based method for selecting features in machine learning that is based on the variance of each feature in the dataset. The method discards features with low variance, as they are less informative for the classification task.\n",
    "\n",
    "##### `The Concept of Variance`\n",
    "Variance is a measure of how much the values of a feature vary from the mean. Features with high variance have a wide range of values, while features with low variance have a narrow range of values.\n",
    "\n",
    "#### `Constant Features`\n",
    "Features that have the same value for all instances in the dataset are known as constant features. Constant features have zero variance, as the values do not vary at all. Such features are not informative for the classification task and can be safely removed from the dataset.\n",
    "\n",
    "#### `Quasi-Constant Features`\n",
    "Quasi-constant features are features that have almost the same value for almost all samples in the dataset. These features have very low variance and are also not informative for the machine learning model. They can be removed from the dataset using the Variance Threshold method.\n",
    "\n",
    "To determine whether a feature is quasi-constant, we can set a threshold for the variance and remove all features with variance below that threshold. A commonly used threshold is 0.01, which means that features with more than 99% of the same value are removed.\n",
    "\n",
    "\n",
    "\n",
    "### `Variance Thresholding`\n",
    "The variance thresholding method works by setting a threshold for the minimum variance of features. Features with variance below the threshold are discarded, while features with variance above the threshold are retained.\n",
    "\n",
    "The appropriate value for the threshold depends on the dataset and the classification task. A higher threshold value retains fewer features, while a lower threshold value retains more features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Interactive Demonstration`\n",
    "Let's now explore the concept of variance thresholding using an interactive demonstration. We will use the Breast Cancer Wisconsin dataset from scikit-learn and apply variance thresholding to the dataset.\n",
    "\n",
    "First, let's import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply variance thresholding to the dataset using scikit-learn's VarianceThreshold class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before thresholding: 30\n",
      "Number of features after thresholding: 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_new = selector.fit_transform(df)\n",
    "print(f\"Number of features before thresholding: {df.shape[1]}\")\n",
    "print(f\"Number of features after thresholding: {X_new.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it returns output in array form so make sure column names are copy beform applying this method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set the threshold value to 0.01, which means that features with variance below 0.01 will be discarded. Let's see how many features are retained and how many are discarded.We can see that the variance thresholding method has discarded 16 features with low variance, retaining only 14 informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variances = df.var()\n",
    "\n",
    "# plot variances\n",
    "plt.plot(sorted(variances, reverse=True))\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Variance of Features')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points to Consider\n",
    "1. Ignores Target Variable: Variance Threshold is a univariate method, meaning it\n",
    "evaluates each feature independently and doesn't consider the relationship between\n",
    "each feature and the target variable. This means it may keep irrelevant features that\n",
    "have a high variance but no relationship with the target, or discard potentially useful\n",
    "features that have a low variance but a strong relationship with the target.\n",
    "\n",
    "\n",
    "2. Ignores Feature Interactions: Variance Threshold doesn't account for interactions\n",
    "between features. A feature with a low variance may become very informative when\n",
    "combined with another feature.\n",
    "\n",
    "\n",
    "3. Sensitive to Data Scaling: Variance Threshold is sensitive to the scale of the data. If\n",
    "features are not on the same scale, the variance will naturally be higher for features\n",
    "with larger values. Therefore, it is important to standardize the features before\n",
    "applying Variance Threshold.\n",
    "\n",
    "\n",
    "4. Arbitrary Threshold Value: It's up to the user to define what constitutes a \"low\"\n",
    "variance. The threshold is not"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:pink'> Correlation-based Feature Selection </span>\n",
    "Correlation-based feature selection is a filter-based method for selecting features in machine learning that is based on the correlation between features. The method discards features that are highly correlated with other features, as they provide redundant information and can negatively impact the performance of the machine learning model.\n",
    "\n",
    "### `The Concept of Correlation`\n",
    "Correlation is a statistical measure that describes the relationship between two variables. In the context of feature selection, correlation is used to measure the relationship between each pair of features in the dataset.\n",
    "\n",
    "### ``Pearson's Correlation Coefficient``\n",
    "The most common measure of correlation is Pearson's correlation coefficient, which is a value between -1 and 1 that describes the linear relationship between two variables. A correlation coefficient of 1 indicates a perfect positive correlation, a correlation coefficient of -1 indicates a perfect negative correlation, and a correlation coefficient of 0 indicates no correlation.\n",
    "\n",
    "### `Correlation-based Feature Selection`\n",
    "The correlation-based feature selection method works by calculating the correlation between each pair of features in the dataset and selecting the features that are least correlated with other features.\n",
    "\n",
    "The appropriate threshold for the correlation coefficient depends on the dataset and the classification task. A higher threshold value retains fewer features, while a lower threshold value retains more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worst concave points', 'worst perimeter', 'mean concave points']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the breast cancer dataset into a Pandas dataframe\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Compute the correlation coefficients between each feature and the target variable (target)\n",
    "corr_matrix = df.corr()\n",
    "corr_with_target = corr_matrix['target']\n",
    "\n",
    "# Sort the correlation coefficients in descending order\n",
    "corr_sorted = corr_with_target.abs().sort_values(ascending=False)\n",
    "\n",
    "# Select the top-ranked features based on the correlation coefficients\n",
    "relevant_features = corr_sorted[1:4].index.tolist()\n",
    "\n",
    "# Print the relevant features\n",
    "print(relevant_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                     1.000000\n",
       "worst concave points       0.793566\n",
       "worst perimeter            0.782914\n",
       "mean concave points        0.776614\n",
       "worst radius               0.776454\n",
       "mean perimeter             0.742636\n",
       "worst area                 0.733825\n",
       "mean radius                0.730029\n",
       "mean area                  0.708984\n",
       "mean concavity             0.696360\n",
       "worst concavity            0.659610\n",
       "mean compactness           0.596534\n",
       "worst compactness          0.590998\n",
       "radius error               0.567134\n",
       "perimeter error            0.556141\n",
       "area error                 0.548236\n",
       "worst texture              0.456903\n",
       "worst smoothness           0.421465\n",
       "worst symmetry             0.416294\n",
       "mean texture               0.415185\n",
       "concave points error       0.408042\n",
       "mean smoothness            0.358560\n",
       "mean symmetry              0.330499\n",
       "worst fractal dimension    0.323872\n",
       "compactness error          0.292999\n",
       "concavity error            0.253730\n",
       "fractal dimension error    0.077972\n",
       "smoothness error           0.067016\n",
       "mean fractal dimension     0.012838\n",
       "texture error              0.008303\n",
       "symmetry error             0.006522\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['target'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "high_corr = corr_matrix.abs() > 0.8\n",
    "mask &= high_corr\n",
    "\n",
    "# Find the indices of the variables to remove\n",
    "to_remove = [column for column in high_corr.columns if any(high_corr[column])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix =df.corr().abs()\n",
    "\n",
    "# Create a mask for highly correlated variables\n",
    "mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "high_corr = corr_matrix.where(mask)\n",
    "to_drop = [column for column in high_corr.columns if any(high_corr[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Get the column names of the DataFrame\n",
    "columns = corr_matrix.columns\n",
    "\n",
    "# Create an empty list to keep track of columns to drop\n",
    "columns_to_drop = []\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i + 1, len(columns)):\n",
    "        # Access the cell of the DataFrame\n",
    "        if corr_matrix.loc[columns[i], columns[j]] > 0.95:\n",
    "            columns_to_drop.append(columns[j])\n",
    "\n",
    "print(len(set(columns_to_drop)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
